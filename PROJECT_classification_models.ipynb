{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94195c7b",
   "metadata": {},
   "source": [
    "Успользуем даннае раннего проекта и проанализируем,как дисбаланс классов и методы его выравнивания влияют на основные метрики\n",
    "и соотношения долей в матрице неточностей.\n",
    "\n",
    "1.ОПИСАНИЕ ДАННЫХ МАССИВА\n",
    "\n",
    "Признаки: RowNumber — индекс строки в данных CustomerId — уникальный идентификатор клиента Surname — фамилия CreditScore — кредитный рейтинг Geography — страна проживания Gender — пол Age — возраст Tenure — сколько лет человек является клиентом банка Balance — баланс на счёте NumOfProducts — количество продуктов банка, используемых клиентом HasCrCard — наличие кредитной карты IsActiveMember — активность клиента EstimatedSalary — предполагаемая зарплата\n",
    "\n",
    "Целевой признак: Exited — факт ухода клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a17da6",
   "metadata": {},
   "source": [
    "Построим и испытаем модели,используя три способа выбора гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in d:\\anaconda\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: cliff in d:\\anaconda\\lib\\site-packages (from optuna) (4.0.0)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in d:\\anaconda\\lib\\site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: alembic in d:\\anaconda\\lib\\site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: colorlog in d:\\anaconda\\lib\\site-packages (from optuna) (6.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: scipy!=1.4.0 in d:\\anaconda\\lib\\site-packages (from optuna) (1.7.3)\n",
      "Requirement already satisfied: PyYAML in d:\\anaconda\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from optuna) (1.21.5)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in d:\\anaconda\\lib\\site-packages (from optuna) (1.4.32)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda\\lib\\site-packages (from sqlalchemy>=1.1.0->optuna) (1.1.1)\n",
      "Requirement already satisfied: Mako in d:\\anaconda\\lib\\site-packages (from alembic->optuna) (1.2.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in d:\\anaconda\\lib\\site-packages (from cliff->optuna) (4.0.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in d:\\anaconda\\lib\\site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in d:\\anaconda\\lib\\site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in d:\\anaconda\\lib\\site-packages (from cliff->optuna) (3.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\anaconda\\lib\\site-packages (from cliff->optuna) (4.11.3)\n",
      "Requirement already satisfied: attrs>=16.3.0 in d:\\anaconda\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in d:\\anaconda\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: pyreadline3 in d:\\anaconda\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: pyperclip>=1.6 in d:\\anaconda\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda\\lib\\site-packages (from importlib-metadata>=4.4->cliff->optuna) (3.7.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from stevedore>=2.0.1->cliff->optuna) (5.10.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in d:\\anaconda\\lib\\site-packages (from Mako->alembic->optuna) (2.0.1)\n",
      "Requirement already satisfied: scikit-plot in d:\\anaconda\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: scipy>=0.9 in d:\\anaconda\\lib\\site-packages (from scikit-plot) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in d:\\anaconda\\lib\\site-packages (from scikit-plot) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.10 in d:\\anaconda\\lib\\site-packages (from scikit-plot) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in d:\\anaconda\\lib\\site-packages (from scikit-plot) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (2.2.0)\n",
      "Requirement already satisfied: lightgbm in d:\\anaconda\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in d:\\anaconda\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: wheel in d:\\anaconda\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.0.6-cp39-none-win_amd64.whl (73.9 MB)\n",
      "Requirement already satisfied: plotly in d:\\anaconda\\lib\\site-packages (from catboost) (5.6.0)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from catboost) (1.7.3)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda\\lib\\site-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in d:\\anaconda\\lib\\site-packages (from catboost) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in d:\\anaconda\\lib\\site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\anaconda\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in d:\\anaconda\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.0.6 graphviz-0.20.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "!pip install optuna\n",
    "import joblib \n",
    "import optuna \n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "\n",
    "!pip install scikit-plot\n",
    "import scikitplot as skplt\n",
    "\n",
    "!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "!pip install catboost\n",
    "import catboost\n",
    "from catboost import Pool,CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost.utils import eval_metric\n",
    "from catboost.utils import get_fpr_curve\n",
    "from catboost.utils import get_fnr_curve\n",
    "from catboost.utils import select_threshold\n",
    "from catboost.utils import get_roc_curve\n",
    "from catboost.utils import get_confusion_matrix\n",
    "\n",
    "!pip3 install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/Churn.csv')\n",
    "                       \n",
    "except:\n",
    "                       \n",
    "    data = pd.read_csv('C:/Users/анатолий/Documents/datasets/Churn.csv')\n",
    "data=data.rename(columns=str.lower)#  названия столбцов перевели в строковый    \n",
    "print(data.shape)    \n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606e3a0",
   "metadata": {},
   "source": [
    "ИТАК видим 3 признака object фамилия,страна проживания и пол. В столбце с временем продолжительности нахождения в качестве клиента банка 909 пропущенных значений(~ 10% ) и их заполним медианой посмотрим как изменится тип данных.Остальные столбцы int и float. Посмотрим дисбаланс классов .Поработаем с кодированием категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acbbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['geography'].sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf022c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['geography'] == 'Germany']['geography'].unique().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82849d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['rownumber','customerid','surname'],axis=1)\n",
    "data.info()\n",
    "print(data.dtypes)\n",
    "data.isna().sum()\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189cd69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tenure'] = data['tenure'].fillna(data['tenure'].median())# заполним пропуски медианой\n",
    "display(data.head())\n",
    "print(data.isna().sum())\n",
    "data.info()\n",
    "types = pd.DataFrame(data.dtypes)\n",
    "print('Столбцы с категориальными данными:\\n',list(types[types[0] == 'object'].index) )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe = pd.get_dummies(data,drop_first=True)\n",
    "\n",
    "features = data_ohe.drop(['exited'],axis=1)\n",
    "target = data_ohe['exited']\n",
    "\n",
    "# оставим для теста 25% выборки а оставшиеся 75% разобьем на тренировочную и валидационную\n",
    "features_train,features_test,target_train,target_test =\\\n",
    "                                                     train_test_split(features,target,\\\n",
    "                                                        test_size = 0.25,random_state = 12345,\\\n",
    "                                                                     stratify=target)\n",
    "print('Размер тренировочной выборки',features_train.shape, target_train.shape)\n",
    "print('Размер тестовой выборки',features_test.shape, target_test.shape)    # с размерностями ОК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pipe_log=make_pipeline(StandardScaler(),LogisticRegression(random_state=12345))\n",
    "param_grid = {\n",
    "              \"penalty\": [\"l1\", \"l2\"],\n",
    "              \"C\" :[0.01,0.1,1.0] ,\n",
    "              \"fit_intercept\": [True, False],\n",
    "              \n",
    "              \"solver\": [\"liblinear\", \"saga\"]\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(multi_class=\"auto\", max_iter=10), param_grid, cv=5)\n",
    "grid = grid.fit(features_train, target_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_classifier = LogisticRegression(**grid.best_params_)\n",
    "lgr_classifier.fit(features_train,target_train)\n",
    "pred = lgr_classifier.predict(features_test)\n",
    "\n",
    "print(classification_report(target_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.estimators.plot_learning_curve(lgr_classifier,features_train,target_train ,\n",
    "                                     cv=7, shuffle=True, scoring=\"f1\",\n",
    "                                     n_jobs=-1, figsize=(6,4), title_fontsize=\"large\", text_fontsize=\"large\",\n",
    "                                     title=\" LogisticRegression Learning Curve\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e29e82",
   "metadata": {},
   "source": [
    "ИТАК:\n",
    "Лучшая мера f1 модели на обучающей выборке:0.32\n",
    "Лучший параметр регуляризации и пенальти на обучающей выборке: C=10,penalty: 'l2'}\n",
    "Мера f1 модели LogisticRegression(random_state=12345,C=10,penalty=l2) на valid выборке:0.31\n",
    "Логистическую регрессию отбросим из рассмотрения в виду малости меры f1.\n",
    "Кривая проверки для LogisticRegression показывает что размера выборки достаточно,но повысить значение\n",
    "меры f1 не получится на этой модели.\n",
    "Параметр С=10 обратной регуляризации дает максимум меры f1 и видим большую погрешность на кривой проверки.\n",
    "Может модель так и называется потому как здесь прям все логично "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e0c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#          DecisionTreeClassifier\n",
    "\n",
    "model_dtr = DecisionTreeClassifier()\n",
    "\n",
    "params_grid = {'max_depth':[1,5,9,13,15]}\n",
    "\n",
    "grid = GridSearchCV(model_dtr, param_grid=params_grid,cv=3,verbose=1)\n",
    "\n",
    "dtr_classifier = grid.fit(features_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be04418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtr_classifier.best_score_)\n",
    "print(dtr_classifier.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceea4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtr_classifier =DecisionTreeClassifier(**dtr_classifier.best_params_)# определили модель с лучшими параметрами\n",
    "dtr_classifier.fit(features_train,target_train)\n",
    "\n",
    "pred_test = dtr_classifier.predict(features_test)\n",
    "pred_train = dtr_classifier.predict(features_train)\n",
    "print(classification_report(target_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf99657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выберем гиперпараметры с помощью OPTUNA\n",
    "def objective(trial):\n",
    "    # Define the search space\n",
    "    criterions = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    max_depths = trial.suggest_int('max_depth', 1, 15, 5)\n",
    "    n_estimators = trial.suggest_categorical('n_estimators', [5,15,55])\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                 criterion=criterions,\n",
    "                                 max_depth=max_depths,\n",
    "                                 n_jobs=-1)\n",
    "    f1 = cross_val_score(clf,features,target,scoring=\"f1\").mean()\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09304653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# созадим объект изучения \n",
    "study = optuna.create_study(study_name=\"randomForest_optimization\",\n",
    "                            direction=\"maximize\",\n",
    "                            sampler=TPESampler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bcf81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оптимизация обекта изучения\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Метрика f1 выбранной лучшей модели',study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ad18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# нарисуем историю оптимизации\n",
    "optuna.visualization.matplotlib.plot_optimization_history(study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434cd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для этой оптимизации главные параметры\n",
    "optuna.visualization.matplotlib.plot_param_importances(study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e30f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# таблица процесса оптимизайии\n",
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2db408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# как происходила тренировка до лучшего результата метрики\n",
    "optuna.visualization.matplotlib.plot_edf(study, target_name=\"f1 score \");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95258383",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rfc_classifier = RandomForestClassifier(**study.best_params)# cоздание мадели с лучшими параметрами\n",
    "rfc_classifier.fit(features_train,target_train)\n",
    "pred_train = rfc_classifier.predict(features_train)\n",
    "pred_test = rfc_classifier.predict(features_test)\n",
    "print(classification_report(target_test, pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7774fa61",
   "metadata": {},
   "source": [
    "Для класса 0 с большим значением в балансе классов метрики больше,чем  для класса 1.\n",
    "Получается алгоритм хорошо работает на большем количестве данных - очевидно.\n",
    "Но ниже посмотрим как все проходит на тестовой выборке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39962c7",
   "metadata": {},
   "source": [
    "    Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_frequency = data['exited'].value_counts()\n",
    "print('Распределение меток классов\\n',class_frequency)\n",
    "target.value_counts(normalize='true').plot(kind='bar',grid=True,title='Доли меток классов');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df996c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         расчет метрик с дисбалансом классов\n",
    "\n",
    "print('Перед применением метода кол-во меток со значением 1: {}'.format(sum(target_train == True)))\n",
    "print('Перед применением метода кол-во меток со значением 0: {}'.format(sum(target_train == False)))\n",
    "model_random = rfc_classifier\n",
    "model_random.fit(features_train,target_train)\n",
    "predictions_test_random = model_random.predict(features_test)\n",
    "\n",
    "print('recall : {:.2f}'.format(recall_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_test_random)))\n",
    "print('precision : {:.2f}'.format(precision_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_test_random)))\n",
    "\n",
    "print('  f1  : {:.2f}'.format(f1_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_test_random)))\n",
    "print(classification_report(target_test, predictions_test_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24093ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#       Расчет метрик после балансировки классов методом SMOTE(повышение до большего)\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE()\n",
    "features_train_smote, target_train_smote = smt.fit_resample(features_train, target_train)\n",
    "print('После применения метода SMOTE кол-во меток со значением 1: {}'.format(sum(target_train_smote == True)))\n",
    "print('После применения метода SMOTE кол-во меток со значением 0: {}'.format(sum(target_train_smote == False)))\n",
    "model_smote =  rfc_classifier\n",
    "model_smote.fit(features_train_smote,target_train_smote)\n",
    "predictions_smote = model_smote.predict(features_test)\n",
    "print('recall : {:.2f}'.format(recall_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_smote)))\n",
    "print('precision : {:.2f}'.format(precision_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_smote)))\n",
    "print('   f1  : {:.2f}'.format(f1_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_smote)))\n",
    "print(classification_report(target_test, predictions_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Расчет метрик после балансировки классов методом NearMiss(с понижением до меньшего класса)\n",
    "\n",
    "\n",
    "nm = NearMiss()\n",
    "features_train_miss, target_train_miss = nm.fit_resample(features_train, target_train)\n",
    "print('После применения метода NearMiss кол-во меток со значением 1: {}'.format(sum(target_train_miss == True)))\n",
    "print('После применения метода NearMiss кол-во меток со значением 0: {}'.format(sum(target_train_miss == False)))\n",
    "\n",
    "model_miss = rfc_classifier\n",
    "model_miss.fit(features_train_miss,target_train_miss)\n",
    "predictions_miss = model_miss.predict(features_test)\n",
    "print('recall : {:.2f}'.format(recall_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_miss)))\n",
    "print('precision : {:.2f}'.format(precision_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_miss)))\n",
    "print('   f1  : {:.2f}'.format(f1_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_miss)))\n",
    "print()\n",
    "print(classification_report(target_test, predictions_miss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde629cc",
   "metadata": {},
   "source": [
    "При уменьшении размерности f1 заметно уменьшается по двум классам,а метрика полноты recall уменьшилась для класса 0(большего),но выросла для класса 1(меньшего).Метрика точности precision для класса 0 практически не изменилась, а для класса 1 упала вдвое.\n",
    "Получили:\n",
    "Уменьшение размерности до меньшего класса приводит к увеличению полноты(доли ТР значений) в этом классе и понижению точности \n",
    "в этом меньшем классе - это тоже понятно.\n",
    "\n",
    "Устранение дисбаланса до размеров большего класса(0) привело к уменьшению метрик в классе 1 по точности и росту полноты recall.\n",
    "Это важно для предсказаний классов для разных задач классификации.\n",
    "\n",
    "Далее построим ROC кривые и матрицы неточностей для разных способов балансировки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0d7e4",
   "metadata": {},
   "source": [
    "Постороим ROC кривые в зависимости от способа выравнивания дисбаланса классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_classifier.fit(features_train, target_train)\n",
    "lr_probs = rfc_classifier.predict_proba(features_test)# получаем предказания\n",
    "lr_probs = lr_probs[:, 1]# сохраняем вероятности только для положительного исхода\n",
    "fpr, tpr, treshold = roc_curve(target_test, lr_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "model_smote.fit(features_train_smote,target_train_smote)\n",
    "lr_probs1 = model_smote.predict_proba(features_test)\n",
    "lr_probs1 = lr_probs1[:, 1]\n",
    "fpr1, tpr1, treshold1 = roc_curve(target_test, lr_probs1)\n",
    "roc_auc = auc(fpr1, tpr1)\n",
    "\n",
    "model_miss.fit(features_train_miss,target_train_miss)\n",
    "lr_probs2 = model_miss.predict_proba(features_test)\n",
    "lr_probs2 = lr_probs2[:, 1]\n",
    "fpr2, tpr2, treshold2 = roc_curve(target_test, lr_probs2)\n",
    "roc_auc = auc(fpr2, tpr2)\n",
    "\n",
    "model_random_balance =RandomForestClassifier(random_state=12345,n_estimators=55,max_depth=11,\\\n",
    "                                             criterion= 'entropy',class_weight='balanced')\n",
    "\n",
    "model_random_balance.fit(features_train,target_train).predict_proba(features_test)\n",
    "lr_probs3 = model_random_balance.predict_proba(features_test)\n",
    "lr_probs3 = lr_probs3[:, 1]\n",
    "fpr3, tpr3, treshold3 = roc_curve(target_test, lr_probs3)\n",
    "roc_auc = auc(fpr3, tpr3)\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(9,5))\n",
    "ax=fig.add_subplot()        \n",
    "plt.plot([0, 1], [0, 1], color='orange', linestyle='--');\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "roc_auc3 = auc(fpr3, tpr3)\n",
    "ax.plot(fpr, tpr,color='blue',label='ROC кривая до балансировки (area = %0.2f)' % roc_auc)\n",
    "ax.plot(fpr1, tpr1, color = 'green',label='ROC кривая с балансировкой SMOTE(area = %0.2f)' % roc_auc1) \n",
    "ax.plot(fpr2, tpr2,color='red',label='ROC кривая с балансировкой NearMiss(area = %0.2f)' % roc_auc2)\n",
    "ax.plot(fpr3, tpr3,color='black',label='ROC кривая с балансировкой class_weight=balanced (area = %0.2f)' % roc_auc3)\n",
    "\n",
    "plt.xlabel('Доля ложно-положительных прогнозов(FPR)')\n",
    "plt.ylabel('Доля истинно-положительных прогнозов(TPR)')\n",
    "plt.minorticks_on()\n",
    "plt.grid(which='major',color='#333',linewidth=1)#большая сетка \n",
    "plt.grid(which='minor',color='#aaa',ls=':')\n",
    "plt.title('ROC кривые до и после балансировки классов для модели RandomForestClassifier')\n",
    "\n",
    "plt.legend(loc=\"best\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f2360",
   "metadata": {},
   "source": [
    "Видим,что понижение размерности до меньшего класса в дисбалансе классов уменьшает площадь под ROC кривой,тогда как \n",
    "для несбаланированного размера классов и способа class_weight='balanced' площадь почти одинаковая.\n",
    "SMOTE дает чуть меньшую площадь.\n",
    "Теперь рассмотрим как влияет балансировка на доли предсказываемых классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285b398f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "\n",
    "confmat1=confusion_matrix(y_true=target_test,y_pred=pred_test)\n",
    "print('Матрица неточностей до балансировки классов :',  confmat1)\n",
    "print('До балансировки f1  : {:.2f}'.format(f1_score(y_true=target_test,\\\n",
    "                                                                y_pred=pred_test)))\n",
    "plot_confusion_matrix(estimator=rfc_classifier, X=features_test, y_true=target_test,\\\n",
    "                     normalize='true', cmap='Blues',ax=ax1);\n",
    "ax1.set_title('до балансировки')\n",
    "\n",
    "\n",
    "confmat2=confusion_matrix(y_true=target_test,y_pred=predictions_smote)\n",
    "print('Матрица неточностей для SMOTE :',  confmat2)\n",
    "print('SMOTE f1  : {:.2f}'.format(f1_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_smote)))\n",
    "plot_confusion_matrix(estimator=model_smote, X=features_test, y_true=target_test,\\\n",
    "                     normalize='true',cmap='Blues',ax=ax2);\n",
    "ax2.set_title('балансиpовка SMOTE')\n",
    "\n",
    "predictions_test_balance = model_random_balance.fit(features_train,target_train).predict(features_test)\n",
    "confmat3=confusion_matrix(y_true=target_test,y_pred=predictions_test_balance)\n",
    "print('Матрица модели class_weight=balanced :',  confmat3)\n",
    "print('class_weight=balanced  f1  : {:.2f}'.format(f1_score(y_true=target_test,\\\n",
    "                                                                y_pred=predictions_test_balance)))\n",
    "plot_confusion_matrix(estimator=model_random_balance, X=features_test, y_true=target_test,\\\n",
    "                     normalize='true', cmap='Blues',ax=ax3);\n",
    "ax3.set_title(\"class_weight='balanced' \");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563dbd2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confmat_miss=confusion_matrix(y_true=target_test,y_pred=predictions_miss)\n",
    "print('Матрица неточностей для NearMiss :',  confmat_miss)\n",
    "print(' NearMiss  f1  : {:.2f}'.format(f1_score(y_true=target_test,\\\n",
    "                                                               y_pred=predictions_miss)))\n",
    "\n",
    "plot_confusion_matrix(estimator=model_miss, X=features_test, y_true=target_test,\\\n",
    "                    normalize='true',cmap='Blues');\n",
    "ax.set_title('балансировка NearMiss');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697fcb18",
   "metadata": {},
   "source": [
    "Видим что балансировка особой роли в данном случае не играет но при уменьшении дисбаланса метрика f1 падает\n",
    "\n",
    "НО:Для способа балансировки class_weight='balanced' получили самое большое значение f1 и соответственно \n",
    "лучшее разделения по TP и TN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d4ce7f",
   "metadata": {},
   "source": [
    "Рассмотрим дополнительно бустинговую модель Catboost\n",
    "\n",
    "АТРИБУТЫ:\n",
    "best_score_ - Возвращает лучший балл модели.\n",
    "classes_ - Возвращает список классов для задачи классификации.\n",
    "feature_names_ — возвращает список имен компонентов.\n",
    "feature_importances_ — возвращает важность каждой функции для каждого алгоритма.\n",
    "learning_rate_ - Возвращает скорость обучения алгоритма.\n",
    "random_seed_ — возвращает случайное семя, из которого были назначены исходные веса модели.\n",
    "tree_count_ - Возвращает количество деревьев в ансамбле.\n",
    "n_features_in_ — возвращает количество функций, используемых для обучения модели.\n",
    "evals_result_ - Возвращает словарь оценки. Если мы предоставили оценочный набор, то результаты оценки для него будут включены.\n",
    "\n",
    "МЕТОДИКА:\n",
    "get_best_score() - Возвращает лучший балл оценщика.\n",
    "get_params() - Возвращает параметры, которые были заданы в качестве словаря при создании оценщика CatBoost и их значения в виде словаря.\n",
    "get_all_params() - Возвращает список всех параметров оценщика CatBoost и их значений в виде словаря.\n",
    "get_cat_feature_indices() - Возвращает список индексов, который имеет категориальные признаки.\n",
    "get_feature_importance() - Возвращает важность индивидуального признака в соответствии с обученной моделью.\n",
    "shrink(ntree_end, ntree_start=0) - Он принимает два аргумента, которые являются конечным деревом, и начинает дерево сжимать ансамбль, чтобы включить только деревья, которые входят в этот диапазон индекса, отбрасывая все другие деревья.\n",
    "set_params() - Может быть использован для задания параметров оценщика. Обратите внимание, что этот метод будет работать только перед моделью обучения.\n",
    "calc_leaf_indexes(data, ntree_start=0,ntree_end=0) - Он принимает в качестве входных данных и возвращает индекс листа в каждом дереве, который использовался для прогнозирования выборки. Выходные данные этой функции будут . Он вернет индекс листьев всех деревьев для образца.n_samples x n_trees\n",
    "get_leaf_values() - Возвращает фактические значения листьев деревьев в ансамбле.\n",
    "get_leaf_weights() - Возвращает вес листьев для каждого листа деревьев в ансамбле."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f14123",
   "metadata": {},
   "source": [
    "Посмотрим работу модели без предварительной кодировки не числовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['geography']=data['geography'].astype('category')\n",
    "data['gender']=data['gender'].astype('category')\n",
    "X = data.drop(['exited'],axis=1)\n",
    "y = data['exited']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,\\\n",
    "                                                        test_size = 0.25,random_state = 12345,\\\n",
    "                                                                     stratify=y)\n",
    "\n",
    "print('Размер тренировочной выборки',X_train.shape, y_train.shape)\n",
    "print('Размер тестовой выборки',X_test.shape, y_test.shape)    # с размерностями ОК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde9de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e8144",
   "metadata": {},
   "source": [
    "Рассмотрим модель с базовами параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd9aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = CatBoostClassifier(iterations=100, verbose=50, eval_metric= 'F1')\n",
    "cat_features_index = [ 1, 2]\n",
    "booster.fit(X_train, y_train,\n",
    "            eval_set=(X_test, y_test),\n",
    "            cat_features=cat_features_index,plot=True);\n",
    " \n",
    "booster.set_feature_names(X_train.columns.tolist())\n",
    "\n",
    "test_preds = booster.predict(X_test)\n",
    "train_preds = booster.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"\\nTest  Accuracy : %.2f\"%booster.score(X_test, y_test))\n",
    "print(\"Train Accuracy : %.2f\"%booster.score(X_train, y_train))\n",
    "print('Метрика f1=', f1_score(y_true=y_test,y_pred=test_preds))\n",
    "print('Список всех параметров модели',booster.get_all_params())\n",
    "print('Список заданных параметров',booster.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "booster.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f04706",
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=200,\n",
    "    learning_rate=0.03,\n",
    ")\n",
    "booster.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features_index,\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a820837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from catboost.utils import get_roc_curve\n",
    "#import sklearn\n",
    "#from sklearn import metrics\n",
    "\n",
    "eval_pool = Pool(X_test, y_test, cat_features=cat_features_index)\n",
    "curve = get_roc_curve(booster, eval_pool)\n",
    "(fpr, tpr, thresholds) = curve\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbe431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc, alpha=0.5)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('Receiver operating characteristic', fontsize=20)\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from catboost.utils import get_fpr_curve\n",
    "#from catboost.utils import get_fnr_curve\n",
    "\n",
    "(thresholds, fpr) = get_fpr_curve(curve=curve)\n",
    "(thresholds, fnr) = get_fnr_curve(curve=curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3f3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(thresholds, fpr, color='blue', lw=lw, label='FPR', alpha=0.5)\n",
    "plt.plot(thresholds, fnr, color='green', lw=lw, label='FNR', alpha=0.5)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Threshold', fontsize=16)\n",
    "plt.ylabel('Error Rate', fontsize=16)\n",
    "plt.title('FPR-FNR curves', fontsize=20)\n",
    "plt.legend(loc=\"lower left\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b61711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# порог для заданных долей FN FP\n",
    "from catboost.utils import select_threshold\n",
    "print(select_threshold(model=booster, data=eval_pool, FNR=0.01))\n",
    "print(select_threshold(model=booster, data=eval_pool, FPR=0.01))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1cb3c",
   "metadata": {},
   "source": [
    "Потренируем модель на скорость и определим параметры для быстрой минимизации функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46144f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем скорость обучения для параметров\n",
    "fast_model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=150,\n",
    "    learning_rate=0.1,\n",
    "    boosting_type='Plain',\n",
    "    bootstrap_type='Bernoulli',\n",
    "    subsample=0.25,\n",
    "    one_hot_max_size=25,\n",
    "    rsm=0.5,\n",
    "    leaf_estimation_iterations=5,\n",
    "    max_ctr_complexity=1)\n",
    "\n",
    "fast_model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features_index,\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07834ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=1000,\n",
    "    learning_rate=0.03,\n",
    "    l2_leaf_reg=3,\n",
    "    bagging_temperature=1,\n",
    "    random_strength=1,\n",
    "    one_hot_max_size=2,\n",
    "    leaf_estimation_method='Newton'\n",
    ")\n",
    "tunned_model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features_index,\n",
    "    verbose=False,\n",
    "    eval_set=(X_test, y_test),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db773b8",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры и найдем лучшую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeec073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(eval_metric= 'F1')\n",
    "\n",
    "params = {\n",
    "            'iterations':[50,100,150],\n",
    "            'learning_rate':[0.01, 0.1, 0.5],\n",
    "            'bootstrap_type':['Bayesian', 'No']}\n",
    "            \n",
    "search_results = model.grid_search(params, features_train, target_train,cv=5,stratified=True,verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(features_train, target_train,\n",
    "           eval_set=(features_test, target_test),\n",
    "            plot=True);\n",
    "model.set_feature_names(features_train.columns.tolist()) \n",
    "\n",
    "test_preds = model.predict(features_test)\n",
    "train_preds = model.predict(features_train)\n",
    "\n",
    "print(\"\\nTest  Accuracy : %.2f\"%model.score(features_test, target_test))\n",
    "print(\"Train Accuracy : %.2f\"%model.score(features_train, target_train))\n",
    "print('Метрика f1=', f1_score(y_true=target_test,y_pred=test_preds))\n",
    "print(classification_report(target_test,test_preds ))\n",
    "print(\"\\nЛучшие выбранные параметры : \", search_results['params'])\n",
    "\n",
    "print(\"Параметры заданные при создании модели : \",model.get_params())\n",
    "print(\"\\nВсе возможные параметры этой модели : \",model.get_all_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определили лучшие параметры\n",
    "cv_results = pd.DataFrame(search_results[\"cv_results\"])\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = get_confusion_matrix(model, Pool(features_train, target_train))\n",
    "print('Матрица ошибок модели',cm)\n",
    "plot_confusion_matrix(estimator=model, X=features_test, y_true=target_test,\\\n",
    "                    normalize='true',cmap='Blues');\n",
    "plt.title('Матрица ошибок Catboost');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc63ab",
   "metadata": {},
   "source": [
    "Результат очень хороший для TN меток в нашем случае класс 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ee1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = model.predict_proba(features_test)\n",
    "\n",
    "skplt.metrics.plot_roc_curve(target_test, lr_probs,\n",
    "                       title=\"Digits ROC Curve\", figsize=(12,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a76111",
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall_curve(target_test, lr_probs,\n",
    "                       title=\"Digits Precision-Recall Curve\", figsize=(12,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f378ef8",
   "metadata": {},
   "source": [
    "Статистика КС (статистика Колмогорова-Смирнова) представляет собой максимальную разницу между кумулятивной истинно-положительной и кумулятивной ложноположительной скоростью. Он отражает способность модели отличать положительные ярлыки от отрицательных. График статистики KS предназначен только для задач двоичной классификации.\n",
    "Мы впервые обучили случайный лесной классификатор на данных. Затем мы передали оригинальные метки тестов и предсказали вероятности тестирования с помощью модели случайного обучения леса, чтобы построить диаграмму статистики KS.plot_ks_statistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_probas = rfc_classifier.predict_proba(features_test)\n",
    "skplt.metrics.plot_ks_statistic(target_test, predict_probas, figsize=(10,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a989e",
   "metadata": {},
   "source": [
    "Диаграмма кумулятивного прироста говорит нам о проценте выборок в данной категории, которые были действительно предсказаны путем таргетинга на процент от общего числа выборок. Это означает, что когда мы взяли, что многие проценты выборок из общего процента, который мы получаем от кривой для оси Y, являются метками, которые действительно были угаданы моделью из общего числа образцов этого класса в таком количестве выборок. Пунктирная линия на графике является базовой кривой (модель случайного угадывания), и наша модель должна работать лучше, чем она, и обе кривые класса должны быть выше нее в идеале. Кумулятивная кривая прибыли предназначена только для задач двоичной классификации.\n",
    "\n",
    "Нам нужно передать исходные метки данных и предсказанные вероятности обученной моделью, чтобы построить кумулятивную кривую прибыли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_cumulative_gain(target_test, predict_probas, figsize=(10,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0d3fa",
   "metadata": {},
   "source": [
    "Диаграмма точности прогнозов выводится из кумулятивной диаграммы путем взятия отношения кумулятивного прироста для каждой кривой к базовому уровню и отображения этого соотношения на оси Y. Ось X имеет то же значение, что и приведенная выше диаграмма. Кривая подъема предназначена только для задач двоичной классификации.\n",
    "\n",
    "Нам нужно передать его исходные метки данных и предсказанные вероятности обученной моделью, чтобы построить кривую подъема"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae305897",
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_lift_curve(target_test, predict_probas, figsize=(10,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e06d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probas = lgr_classifier.fit(features_train, target_train).predict_proba(features_test)\n",
    "rf_probas = rfc_classifier.fit(features_train, target_train).predict_proba(features_test)\n",
    "dt_probas = dtr_classifier.fit(features_train, target_train).predict_proba(features_test)\n",
    "cbc_probas= model.fit(features_train, target_train).predict_proba(features_test)\n",
    "probas_list = [lr_probas, rf_probas,dt_probas,cbc_probas]\n",
    "clf_names = ['Logistic Regression', 'Random Forest', 'DecisionTree','Catboost']\n",
    "skplt.metrics.plot_calibration_curve(target_test,\n",
    "                                     probas_list,\n",
    "                                     clf_names, n_bins=15,\n",
    "                                     figsize=(12,6)\n",
    "                                     );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4bba59",
   "metadata": {},
   "source": [
    "Кроме логистической модели все остальные хорошо отработали по классам "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
